{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Entrenamiento de clasificador de ojos**",
   "id": "b20156c0800cf77d"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-17T17:36:59.195206Z",
     "start_time": "2026-02-17T17:36:54.358730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mediapipe_model_maker import image_classifier\n",
    "\n",
    "from inference.classifier_run import create_clasifier\n",
    "\n",
    "# importar datos\n",
    "TRAIN_PATH = \"MRL/train\"\n",
    "VALID_PATH = \"MRL/val\"\n",
    "TEST_PATH = \"MRL/test\"\n",
    "data_train = image_classifier.Dataset.from_folder(TRAIN_PATH)\n",
    "data_valid = image_classifier.Dataset.from_folder(VALID_PATH)\n",
    "data_test = image_classifier.Dataset.from_folder(TEST_PATH)"
   ],
   "id": "2dbd7d8802e4335b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 12:36:54.688009: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-02-17 12:36:54.720853: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-02-17 12:36:54.720895: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-02-17 12:36:54.721826: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-02-17 12:36:54.727007: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-02-17 12:36:54.727468: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-17 12:36:55.920084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/edmar/Documents/drowsiness-classification/.venv_train/lib64/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 50937, num_label: 2, labels: awake, sleepy.\n",
      "INFO:tensorflow:Load image with size: 16980, num_label: 2, labels: awake, sleepy.\n",
      "INFO:tensorflow:Load image with size: 16981, num_label: 2, labels: awake, sleepy.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T19:17:22.873034Z",
     "start_time": "2026-02-17T18:57:09.057168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Entrenamiento\n",
    "MODEL_DIR=\"./eye-classifier-a\"\n",
    "SAVE_NAME = \"en0_eye_a.tflite\"\n",
    "QUANTIZED_NAME = \"en0_eye_a.f16.tflite\"\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "model_options = image_classifier.ModelOptions(dropout_rate=0.25)\n",
    "hparams = image_classifier.HParams(\n",
    "    learning_rate=2e-04,\n",
    "    export_dir=MODEL_DIR,\n",
    "    shuffle=True,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "model_arch = image_classifier.SupportedModels.EFFICIENTNET_LITE0\n",
    "options = image_classifier.ImageClassifierOptions(supported_model=model_arch, hparams=hparams, model_options=model_options)\n",
    "\n",
    "classifier = image_classifier.ImageClassifier.create(train_data=data_train, validation_data=data_valid, options=options)"
   ],
   "id": "2b0c824e4457b472",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_1 (KerasLayer)  (None, 1280)              3413024   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3415586 (13.03 MB)\n",
      "Trainable params: 2562 (10.01 KB)\n",
      "Non-trainable params: 3413024 (13.02 MB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Training the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from ./eye-classifier-a/checkpoint/model-0004\n",
      "1591/1591 [==============================] - 1207s 756ms/step - loss: 0.3686 - accuracy: 0.8993 - val_loss: 0.2812 - val_accuracy: 0.9574\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T19:31:54.141773Z",
     "start_time": "2026-02-17T19:27:02.910256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    # Precision en datos de prueba\n",
    "loss, accuracy = classifier.evaluate(data_test)\n",
    "print(f\"Dataset: {TRAIN_PATH}\\nPrecision: {accuracy*100}%\")"
   ],
   "id": "d820cacefbc46b73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531/531 [==============================] - 291s 548ms/step - loss: 0.2812 - accuracy: 0.9582\n",
      "Dataset: MRL/train\n",
      "Precision: 95.82474827766418%\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T19:36:14.122431Z",
     "start_time": "2026-02-17T19:35:39.279873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mediapipe_model_maker import quantization\n",
    "\n",
    "# Guardar y cuantizar\n",
    "classifier.export_model(model_name=SAVE_NAME)\n",
    "config = quantization.QuantizationConfig.for_float16()\n",
    "classifier.export_model(model_name=QUANTIZED_NAME, quantization_config=config)"
   ],
   "id": "557e7b641e218667",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpycmiw0j_/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpycmiw0j_/saved_model/assets\n",
      "2026-02-17 14:35:54.762082: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2026-02-17 14:35:54.762118: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2026-02-17 14:35:54.764172: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpycmiw0j_/saved_model\n",
      "2026-02-17 14:35:54.773045: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2026-02-17 14:35:54.773081: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpycmiw0j_/saved_model\n",
      "2026-02-17 14:35:54.793719: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2026-02-17 14:35:54.803114: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2026-02-17 14:35:55.112096: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpycmiw0j_/saved_model\n",
      "2026-02-17 14:35:55.298378: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 534173 microseconds.\n",
      "2026-02-17 14:35:55.411505: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 103, Total Ops 169, % non-converted = 60.95 %\n",
      " * 103 ARITH ops\n",
      "\n",
      "- arith.constant:  103 occurrences  (f32: 102, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 10)\n",
      "  (f32: 33)\n",
      "  (f32: 16)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully to: ./eye-classifier-a/en0_eye_a.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully to: ./eye-classifier-a/en0_eye_a.tflite\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcz6rmzkf/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpcz6rmzkf/saved_model/assets\n",
      "2026-02-17 14:36:12.905397: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2026-02-17 14:36:12.905439: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2026-02-17 14:36:12.905621: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpcz6rmzkf/saved_model\n",
      "2026-02-17 14:36:12.912813: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2026-02-17 14:36:12.912830: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpcz6rmzkf/saved_model\n",
      "2026-02-17 14:36:12.937125: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2026-02-17 14:36:13.249365: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpcz6rmzkf/saved_model\n",
      "2026-02-17 14:36:13.432986: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 527366 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 103, Total Ops 271, % non-converted = 38.01 %\n",
      " * 103 ARITH ops\n",
      "\n",
      "- arith.constant:  103 occurrences  (f16: 102, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 10)\n",
      "  (f32: 33)\n",
      "  (f32: 16)\n",
      "  (f32: 102)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully to: ./eye-classifier-a/en0_eye_a.f16.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully to: ./eye-classifier-a/en0_eye_a.f16.tflite\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T04:52:22.457371Z",
     "start_time": "2026-02-18T04:52:22.407291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Validacion en FL3D cropped\n",
    "FL3D_VAL = \"FL3D-eyesbig\"\n",
    "data_extval = image_classifier.Dataset.from_folder(FL3D_VAL)\n"
   ],
   "id": "dc3d62f2bb6a299f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 4174, num_label: 2, labels: 1, 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 4174, num_label: 2, labels: 1, 2.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dab5804a66183444"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T04:54:02.362339Z",
     "start_time": "2026-02-18T04:52:31.370967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss, accuracy = classifier.evaluate(data_extval)\n",
    "print(f\"Dataset: {FL3D_VAL}\\nPrecision: {accuracy*100}%\")\n"
   ],
   "id": "43123b98acf21027",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 91s 695ms/step - loss: 0.3935 - accuracy: 0.8632\n",
      "Dataset: <mediapipe_model_maker.python.vision.image_classifier.dataset.Dataset object at 0x7f7ab2d24590>\n",
      "Precision: 86.32007837295532%\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
